{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waste Classification Training (Colab Ready)\n",
    "\n",
    "Notebook này hướng dẫn toàn bộ pipeline: chuẩn bị dữ liệu, huấn luyện mô hình CNN/Transfer Learning, đánh giá và tạo demo Gradio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Thiết lập môi trường\n",
    "- Chạy trên GPU (Runtime → Change runtime type → GPU)\n",
    "- Kết nối Google Drive nếu dữ liệu/model lưu trên đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Mount Google Drive (tùy chọn)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Cài đặt phụ thuộc\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -q albumentations==1.4.7 timm==1.0.3 grad-cam==1.5.5 gradio==4.44.0 scikit-learn==1.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d57b9bd5-ae5f-495f-892f-581258371c44",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Kiem tra tai nguyen Colab\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    import psutil\n",
    "except ImportError:\n",
    "    psutil = None\n",
    "\n",
    "print(\"Tinh trang tai nguyen:\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"- GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"- GPU: chua bat. Vao Runtime > Change runtime type > GPU.\")\n",
    "\n",
    "total, used, free = shutil.disk_usage(\"/\")\n",
    "print(f\"- O dia: {total/1e9:.1f} GB tong | {free/1e9:.1f} GB trong\")\n",
    "\n",
    "if psutil is not None:\n",
    "    ram = psutil.virtual_memory()\n",
    "    print(f\"- RAM: {ram.total/1e9:.1f} GB tong | {ram.available/1e9:.1f} GB kha dung\")\n",
    "else:\n",
    "    print(\"- RAM: cai psutil de hien thi (pip install psutil)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chuẩn bị dự án\n",
    "- Nếu đã upload project lên GitHub, clone trực tiếp.\n",
    "- Nếu làm việc trên Drive, unzip project vào `/content/TrashProject`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Clone hoặc đồng bộ mã nguồn\n",
    "import os, shutil, zipfile, sys\n",
    "\n",
    "PROJECT_PATH = \"/content/TrashProject\"  # chỉnh sửa nếu cần\n",
    "GIT_REPO_URL = \"https://github.com/<your-account>/TrashProject.git\"  # TODO: cập nhật\n",
    "\n",
    "if not os.path.exists(PROJECT_PATH):\n",
    "    !git clone $GIT_REPO_URL $PROJECT_PATH\n",
    "else:\n",
    "    print(f\"Sử dụng thư mục có sẵn: {PROJECT_PATH}\")\n",
    "\n",
    "sys.path.append(PROJECT_PATH)\n",
    "os.chdir(PROJECT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tải và tiền xử lý dữ liệu\n",
    "- Có thể dùng script sẵn có để tải TrashNet về thư mục data/raw.\n",
    "- Hoặc dùng dataset công khai khác/Kaggle ở các cell tiếp theo.\n",
    "- Có thể thay bằng dataset tự thu thập (đưa vào thư mục data/raw).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Tải TrashNet từ GitHub (tùy chọn)\n",
    "import os\n",
    "DOWNLOAD_TRASHNET = False  #@param {type:\"boolean\"}\n",
    "DATA_ROOT = \"/content/TrashProject/data\"  #@param {type:\"string\"}\n",
    "RAW_DATA_DIR = f\"{DATA_ROOT}/raw\"\n",
    "os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
    "if DOWNLOAD_TRASHNET:\n",
    "    !python scripts/download_trashnet.py --output-dir {RAW_DATA_DIR}\n",
    "    print(\"TrashNet downloaded.\")\n",
    "print(f\"Raw data folder: {RAW_DATA_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Tải TrashNet từ Kaggle (tùy chọn)\n",
    "# Yêu cầu tạo ~/.kaggle/kaggle.json trước khi chạy\n",
    "DOWNLOAD_DATA = False  #@param {type:\"boolean\"}\n",
    "DATA_ROOT = \"/content/TrashProject/data\"  #@param {type:\"string\"}\n",
    "\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "\n",
    "if DOWNLOAD_DATA:\n",
    "    !kaggle datasets download -d asdasdasasdas/garbage-classification\n",
    "    with zipfile.ZipFile(\"garbage-classification.zip\", \"r\") as zf:\n",
    "        zf.extractall(DATA_ROOT)\n",
    "    os.remove(\"garbage-classification.zip\")\n",
    "\n",
    "print(f\"Data folder: {DATA_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Tải TACO từ GitHub (tùy chọn)\n",
    "DOWNLOAD_TACO = False  #@param {type:\"boolean\"}\n",
    "DATA_ROOT = \"/content/TrashProject/data\"  #@param {type:\"string\"}\n",
    "RAW_DATA_DIR = f\"{DATA_ROOT}/raw/taco\"\n",
    "os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
    "if DOWNLOAD_TACO:\n",
    "    !python scripts/download_taco.py --output-dir {RAW_DATA_DIR}\n",
    "print(f\"TACO raw data folder: {RAW_DATA_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Tạo train/val/test split (70/20/10)\n",
    "DATA_ROOT = globals().get('DATA_ROOT', '/content/TrashProject/data')\n",
    "from pathlib import Path\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "raw_dir = Path(DATA_ROOT) / \"raw\"\n",
    "train_dir = Path(DATA_ROOT) / \"train\"\n",
    "val_dir = Path(DATA_ROOT) / \"val\"\n",
    "test_dir = Path(DATA_ROOT) / \"test\"\n",
    "\n",
    "for folder in [train_dir, val_dir, test_dir]:\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if raw_dir.exists():\n",
    "    for class_dir in raw_dir.iterdir():\n",
    "        if not class_dir.is_dir():\n",
    "            continue\n",
    "        images = list(class_dir.glob(\"*\"))\n",
    "        random.shuffle(images)\n",
    "        n = len(images)\n",
    "        n_train = int(0.7 * n)\n",
    "        n_val = int(0.2 * n)\n",
    "        splits = {\n",
    "            train_dir / class_dir.name: images[:n_train],\n",
    "            val_dir / class_dir.name: images[n_train:n_train + n_val],\n",
    "            test_dir / class_dir.name: images[n_train + n_val:],\n",
    "        }\n",
    "        for split_dir, split_imgs in splits.items():\n",
    "            split_dir.mkdir(parents=True, exist_ok=True)\n",
    "            for img_path in split_imgs:\n",
    "                shutil.copy(img_path, split_dir / img_path.name)\n",
    "    print(\"Hoàn thành chia tập dữ liệu.\")\n",
    "else:\n",
    "    print(\"Bỏ qua bước chia tập vì không tìm thấy data/raw.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cấu hình và huấn luyện\n",
    "Sử dụng lớp `WasteTrainer` trong `src/training/trainer.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Khoi tao cau hinh huan luyen\n",
    "from pathlib import Path\n",
    "\n",
    "AVAILABLE_MODELS = [\"resnet18\", \"mobilenetv3\", \"efficientnetb0\"]\n",
    "\n",
    "MODEL_LIST = \"resnet18\"  #@param {type:\"string\"}\n",
    "EPOCHS = 15  #@param {type:\"integer\"}\n",
    "IMG_SIZE = 224  #@param {type:\"integer\"}\n",
    "BATCH_SIZE = 32  #@param {type:\"integer\"}\n",
    "NUM_WORKERS = 2  #@param {type:\"integer\"}\n",
    "LOSS = \"focal\"  #@param [\"cross_entropy\", \"focal\"]\n",
    "FOCAL_GAMMA = 2.0  #@param {type:\"number\"}\n",
    "USE_BLUR = False  #@param {type:\"boolean\"}\n",
    "USE_RANDOM_ERASING = False  #@param {type:\"boolean\"}\n",
    "USE_MIXUP = False  #@param {type:\"boolean\"}\n",
    "USE_CUTMIX = False  #@param {type:\"boolean\"}\n",
    "MIXUP_ALPHA = 0.4  #@param {type:\"number\"}\n",
    "CUTMIX_ALPHA = 1.0  #@param {type:\"number\"}\n",
    "OPTIM = \"adamw\"  #@param [\"adam\", \"adamw\", \"sgd\"]\n",
    "LR = 3e-4  #@param {type:\"number\"}\n",
    "WEIGHT_DECAY = 1e-4  #@param {type:\"number\"}\n",
    "SCHEDULER = \"onecycle\"  #@param [\"onecycle\", \"cosine\", \"step\", \"none\"]\n",
    "MAX_LR = 1e-3  #@param {type:\"number\"}\n",
    "DEVICE = \"cuda\"  #@param [\"cuda\", \"cpu\"]\n",
    "LOG_EVERY = 20  #@param {type:\"integer\"}\n",
    "FREEZE_BACKBONE_EPOCHS = 5  #@param {type:\"integer\"}\n",
    "OUTPUT_DIR = \"artifacts\"  #@param {type:\"string\"}\n",
    "SELECT_MODEL_METRIC = \"macro_f1\"  #@param [\"macro_f1\", \"accuracy\", \"macro_precision\", \"macro_recall\"]\n",
    "\n",
    "MODEL_NAMES = [name.strip().lower() for name in MODEL_LIST.split(\",\") if name.strip()]\n",
    "MODEL_NAMES = [name for name in MODEL_NAMES if name in AVAILABLE_MODELS]\n",
    "if not MODEL_NAMES:\n",
    "    MODEL_NAMES = [\"resnet18\"]\n",
    "    print(\"MODEL_LIST khong hop le, su dung mac dinh resnet18.\")\n",
    "\n",
    "from src.training.dataset import DataConfig\n",
    "from src.training.losses import LossConfig\n",
    "from src.training.optim import OptimConfig, SchedulerConfig\n",
    "from src.training.trainer import TrainConfig, WasteTrainer\n",
    "\n",
    "DATA_ROOT = globals().get('DATA_ROOT', '/content/TrashProject/data')\n",
    "data_cfg = DataConfig(\n",
    "    train_dir=Path(DATA_ROOT) / \"train\",\n",
    "    val_dir=Path(DATA_ROOT) / \"val\",\n",
    "    test_dir=Path(DATA_ROOT) / \"test\",\n",
    "    img_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    use_blur=USE_BLUR,\n",
    "    use_random_erasing=USE_RANDOM_ERASING,\n",
    ")\n",
    "\n",
    "loss_cfg = LossConfig(name=LOSS, gamma=FOCAL_GAMMA) if LOSS == \"focal\" else LossConfig(name=LOSS)\n",
    "optim_cfg = OptimConfig(name=OPTIM, lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler_cfg = None\n",
    "if SCHEDULER != \"none\":\n",
    "    scheduler_cfg = SchedulerConfig(name=SCHEDULER, max_lr=MAX_LR)\n",
    "\n",
    "BASE_OUTPUT_DIR = Path(OUTPUT_DIR)\n",
    "BASE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BASE_TRAIN_KWARGS = dict(\n",
    "    data=data_cfg,\n",
    "    loss=loss_cfg,\n",
    "    optim=optim_cfg,\n",
    "    scheduler=scheduler_cfg,\n",
    "    epochs=EPOCHS,\n",
    "    device=DEVICE,\n",
    "    log_every=LOG_EVERY,\n",
    "    freeze_backbone_epochs=FREEZE_BACKBONE_EPOCHS,\n",
    "    use_mixup=USE_MIXUP,\n",
    "    use_cutmix=USE_CUTMIX,\n",
    "    mixup_alpha=MIXUP_ALPHA,\n",
    "    cutmix_alpha=CUTMIX_ALPHA,\n",
    ")\n",
    "\n",
    "print(f\"Models: {MODEL_NAMES}\")\n",
    "print(f\"Epochs: {EPOCHS}, Batch size: {BATCH_SIZE}, LR: {LR}\")\n",
    "print(f\"Loss: {LOSS}, Scheduler: {SCHEDULER}, Freeze epochs: {FREEZE_BACKBONE_EPOCHS}\")\n",
    "print(f\"Artifacts root: {BASE_OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Huan luyen va so sanh mo hinh\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError as exc:\n",
    "    raise RuntimeError('Can install pandas trong moi truong notebook') from exc\n",
    "\n",
    "trained_models = {}\n",
    "results = []\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"===== Huan luyen {model_name} =====\")\n",
    "    cfg = TrainConfig(\n",
    "        model_name=model_name,\n",
    "        output_dir=BASE_OUTPUT_DIR / model_name,\n",
    "        **BASE_TRAIN_KWARGS,\n",
    "    )\n",
    "    trainer = WasteTrainer(cfg)\n",
    "    report, cm = trainer.train()\n",
    "    trained_models[model_name] = {\"trainer\": trainer, \"report\": report, \"cm\": cm}\n",
    "    if report:\n",
    "        macro = report.get(\"macro avg\", {})\n",
    "        results.append({\n",
    "            \"model\": model_name,\n",
    "            \"test_accuracy\": report.get(\"accuracy\"),\n",
    "            \"macro_precision\": macro.get(\"precision\"),\n",
    "            \"macro_recall\": macro.get(\"recall\"),\n",
    "            \"macro_f1\": macro.get(\"f1-score\"),\n",
    "        })\n",
    "    else:\n",
    "        results.append({\n",
    "            \"model\": model_name,\n",
    "            \"test_accuracy\": None,\n",
    "            \"macro_precision\": None,\n",
    "            \"macro_recall\": None,\n",
    "            \"macro_f1\": None,\n",
    "        })\n",
    "    print()\n",
    "\n",
    "MODEL_RESULTS_DF = None\n",
    "best_trainer = None\n",
    "best_report = None\n",
    "best_cm = None\n",
    "best_model_name = None\n",
    "\n",
    "if results:\n",
    "    MODEL_RESULTS_DF = pd.DataFrame(results).set_index(\"model\")\n",
    "    display(MODEL_RESULTS_DF)\n",
    "\n",
    "    metric_series = MODEL_RESULTS_DF[SELECT_MODEL_METRIC]\n",
    "    if metric_series.notna().any():\n",
    "        best_model_name = metric_series.astype(float).idxmax()\n",
    "    else:\n",
    "        best_model_name = MODEL_NAMES[0]\n",
    "        print(\"Khong co chi so hop le tren test, chon mo hinh dau tien.\")\n",
    "    print(f\"Chon mo hinh tot nhat: {best_model_name} (theo {SELECT_MODEL_METRIC})\")\n",
    "    best_info = trained_models[best_model_name]\n",
    "    best_trainer = best_info[\"trainer\"]\n",
    "    best_report = best_info[\"report\"]\n",
    "    best_cm = best_info[\"cm\"]\n",
    "else:\n",
    "    print(\"Khong co ket qua nao. Hay kiem tra data/raw.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0373cef-5237-439c-b0e3-20e0999afb34",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Bao cao chi tiet mo hinh tot nhat\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError as exc:\n",
    "    raise RuntimeError('Can install pandas trong moi truong notebook') from exc\n",
    "\n",
    "if 'best_report' in globals() and best_report:\n",
    "    report_df = pd.DataFrame(best_report).T\n",
    "    display(report_df)\n",
    "else:\n",
    "    print(\"Chua co ket qua nao. Hay chay cell huan luyen truoc.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Hien thi ma tran nham lan\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "if 'best_cm' in globals() and best_cm is not None:\n",
    "    cm_obj = best_cm\n",
    "    cm_np = cm_obj.numpy() if isinstance(cm_obj, torch.Tensor) else cm_obj\n",
    "    labels = list(best_trainer.idx_to_class.values()) if 'best_trainer' in globals() and best_trainer else []\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_np, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Chua co ma tran nham lan. Hay chay cell huan luyen truoc.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Demo Gradio\n",
    "Tải trọng số tốt nhất và tạo UI đơn giản cho phép người dùng upload ảnh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Khoi tao Gradio demo\n",
    "import gradio as gr\n",
    "import gradio_client.utils as gradio_utils\n",
    "\n",
    "if 'best_trainer' not in globals() or best_trainer is None:\n",
    "    raise RuntimeError('Chua co mo hinh huan luyen. Hay chay cell huan luyen truoc.')\n",
    "\n",
    "# Work around Gradio bug when additionalProperties=False produces a bool schema\n",
    "_original_json_schema_to_python_type = gradio_utils._json_schema_to_python_type\n",
    "\n",
    "def _safe_json_schema_to_python_type(schema, defs):\n",
    "    if isinstance(schema, bool):\n",
    "        return 'Any'\n",
    "    return _original_json_schema_to_python_type(schema, defs)\n",
    "\n",
    "gradio_utils._json_schema_to_python_type = _safe_json_schema_to_python_type\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "model = best_trainer.model\n",
    "checkpoint = torch.load(best_trainer.config.output_dir / 'best.pt', map_location=best_trainer.device)\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "model.eval()\n",
    "\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "class_names = [best_trainer.idx_to_class[idx] for idx in sorted(best_trainer.idx_to_class)]\n",
    "\n",
    "def predict(image: Image.Image):\n",
    "    tensor = preprocess(image).unsqueeze(0).to(best_trainer.device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(tensor)\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "    return {class_names[i]: float(probs[i]) for i in range(len(class_names))}\n",
    "\n",
    "gr.Interface(fn=predict, inputs=gr.Image(type='pil'), outputs=gr.Label(num_top_classes=3)).launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Lưu kết quả và tải xuống\n",
    "- Lưu lại mô hình, báo cáo metrics vào Drive.\n",
    "- Đảm bảo cập nhật báo cáo đồ án với bảng kết quả và nhận xét."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. So sánh mô hình\n",
    "Sau khi chạy huấn luyện với các kiến trúc khác nhau, hãy đặt `OUTPUT_DIR` khác nhau cho mỗi lần (ví dụ `artifacts_resnet18`, `artifacts_mobilenet`).\n",
    "Cell dưới đây sẽ đọc các thư mục output đó, tổng hợp Accuracy/Macro F1 trên test và best val acc để bạn so sánh nhanh.\n",
    "Chỉnh sửa biến `EXPERIMENT_DIRS` theo danh sách mô hình bạn đã huấn luyện.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title Tổng hợp kết quả các mô hình đã huấn luyện\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "EXPERIMENT_DIRS = {\n",
    "    \"resnet18\": \"/content/TrashProject/artifacts_resnet18\",\n",
    "    \"mobilenetv3\": \"/content/TrashProject/artifacts_mobilenetv3\",\n",
    "    \"efficientnetb0\": \"/content/TrashProject/artifacts_efficientnetb0\",\n",
    "}  # Chỉnh sửa theo các output_dir bạn đã dùng\n",
    "\n",
    "summary = []\n",
    "for name, dir_path in EXPERIMENT_DIRS.items():\n",
    "    dir_path = Path(dir_path)\n",
    "    if not dir_path.exists():\n",
    "        print(f\"[WARN] {dir_path} không tồn tại, bỏ qua.\")\n",
    "        continue\n",
    "    report_path = dir_path / \"classification_report.pth\"\n",
    "    history_path = dir_path / \"history.pth\"\n",
    "    macro_f1 = accuracy = best_val_acc = None\n",
    "\n",
    "    if report_path.exists():\n",
    "        report = torch.load(report_path)\n",
    "        macro_f1 = report.get(\"macro avg\", {}).get(\"f1-score\")\n",
    "        accuracy = report.get(\"accuracy\")\n",
    "    if history_path.exists():\n",
    "        history = torch.load(history_path)\n",
    "        if isinstance(history, dict) and \"val_acc\" in history:\n",
    "            best_val_acc = max(history[\"val_acc\"])\n",
    "\n",
    "    summary.append({\n",
    "        \"model\": name,\n",
    "        \"output_dir\": str(dir_path),\n",
    "        \"test_accuracy\": accuracy,\n",
    "        \"test_macro_f1\": macro_f1,\n",
    "        \"best_val_acc\": best_val_acc,\n",
    "    })\n",
    "\n",
    "if not summary:\n",
    "    print(\"Chưa có kết quả nào. Hãy chạy huấn luyện và lưu output_dir riêng cho từng mô hình.\")\n",
    "else:\n",
    "    header = (\"Model\", \"Output Dir\", \"Test Acc\", \"Test Macro F1\", \"Best Val Acc\")\n",
    "    row_fmt = \"{:<15} {:<40} {:>11} {:>15} {:>13}\"\n",
    "    print(row_fmt.format(*header))\n",
    "    print('-' * 96)\n",
    "    for row in summary:\n",
    "        print(row_fmt.format(\n",
    "            row[\"model\"],\n",
    "            row[\"output_dir\"],\n",
    "            f\"{row['test_accuracy']:.3f}\" if row[\"test_accuracy\"] is not None else \"n/a\",\n",
    "            f\"{row['test_macro_f1']:.3f}\" if row[\"test_macro_f1\"] is not None else \"n/a\",\n",
    "            f\"{row['best_val_acc']:.3f}\" if row[\"best_val_acc\"] is not None else \"n/a\",\n",
    "        ))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}