{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Waste Classification Training (Colab Ready)\n",
        "\n",
        "Notebook này hướng dẫn toàn bộ pipeline: chuẩn bị dữ liệu, huấn luyện mô hình CNN/Transfer Learning, đánh giá và tạo demo Gradio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Thiết lập môi trường\n",
        "- Chạy trên GPU (Runtime → Change runtime type → GPU)\n",
        "- Kết nối Google Drive nếu dữ liệu/model lưu trên đó."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Mount Google Drive (tùy chọn)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Cài đặt phụ thuộc\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install -q albumentations==1.4.7 timm==1.0.3 grad-cam==1.5.5 gradio==4.44.0 scikit-learn==1.5.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d57b9bd5-ae5f-495f-892f-581258371c44",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Kiem tra tai nguyen Colab\n",
        "import shutil\n",
        "import torch\n",
        "\n",
        "try:\n",
        "    import psutil\n",
        "except ImportError:\n",
        "    psutil = None\n",
        "\n",
        "print(\"Tinh trang tai nguyen:\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"- GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"- GPU: chua bat. Vao Runtime > Change runtime type > GPU.\")\n",
        "\n",
        "total, used, free = shutil.disk_usage(\"/\")\n",
        "print(f\"- O dia: {total/1e9:.1f} GB tong | {free/1e9:.1f} GB trong\")\n",
        "\n",
        "if psutil is not None:\n",
        "    ram = psutil.virtual_memory()\n",
        "    print(f\"- RAM: {ram.total/1e9:.1f} GB tong | {ram.available/1e9:.1f} GB kha dung\")\n",
        "else:\n",
        "    print(\"- RAM: cai psutil de hien thi (pip install psutil)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Chuẩn bị dự án\n",
        "- Nếu đã upload project lên GitHub, clone trực tiếp.\n",
        "- Nếu làm việc trên Drive, unzip project vào `/content/TrashProject`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Clone hoặc đồng bộ mã nguồn\n",
        "import os, shutil, zipfile, sys\n",
        "\n",
        "PROJECT_PATH = \"/content/TrashProject\"  # chỉnh sửa nếu cần\n",
        "GIT_REPO_URL = \"https://github.com/<your-account>/TrashProject.git\"  # TODO: cập nhật\n",
        "\n",
        "if not os.path.exists(PROJECT_PATH):\n",
        "    !git clone $GIT_REPO_URL $PROJECT_PATH\n",
        "else:\n",
        "    print(f\"Sử dụng thư mục có sẵn: {PROJECT_PATH}\")\n",
        "\n",
        "sys.path.append(PROJECT_PATH)\n",
        "os.chdir(PROJECT_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Tải và tiền xử lý dữ liệu\n",
        "- Có thể dùng script sẵn có để tải TrashNet về thư mục data/raw.\n",
        "- Hoặc dùng dataset công khai khác/Kaggle ở các cell tiếp theo.\n",
        "- Có thể thay bằng dataset tự thu thập (đưa vào thư mục data/raw).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Tải TrashNet từ GitHub (tùy chọn)\n",
        "import os\n",
        "DOWNLOAD_TRASHNET = False  #@param {type:\"boolean\"}\n",
        "DATA_ROOT = \"/content/TrashProject/data\"  #@param {type:\"string\"}\n",
        "RAW_DATA_DIR = f\"{DATA_ROOT}/raw\"\n",
        "os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
        "if DOWNLOAD_TRASHNET:\n",
        "    !python scripts/download_trashnet.py --output-dir {RAW_DATA_DIR}\n",
        "    print(\"TrashNet downloaded.\")\n",
        "print(f\"Raw data folder: {RAW_DATA_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Tải TrashNet từ Kaggle (tùy chọn)\n",
        "# Yêu cầu tạo ~/.kaggle/kaggle.json trước khi chạy\n",
        "DOWNLOAD_DATA = False  #@param {type:\"boolean\"}\n",
        "DATA_ROOT = \"/content/TrashProject/data\"  #@param {type:\"string\"}\n",
        "\n",
        "os.makedirs(DATA_ROOT, exist_ok=True)\n",
        "\n",
        "if DOWNLOAD_DATA:\n",
        "    !kaggle datasets download -d asdasdasasdas/garbage-classification\n",
        "    with zipfile.ZipFile(\"garbage-classification.zip\", \"r\") as zf:\n",
        "        zf.extractall(DATA_ROOT)\n",
        "    os.remove(\"garbage-classification.zip\")\n",
        "\n",
        "print(f\"Data folder: {DATA_ROOT}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Tạo train/val/test split (70/20/10)\n",
        "DATA_ROOT = globals().get('DATA_ROOT', '/content/TrashProject/data')\n",
        "from pathlib import Path\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "raw_dir = Path(DATA_ROOT) / \"raw\"\n",
        "train_dir = Path(DATA_ROOT) / \"train\"\n",
        "val_dir = Path(DATA_ROOT) / \"val\"\n",
        "test_dir = Path(DATA_ROOT) / \"test\"\n",
        "\n",
        "for folder in [train_dir, val_dir, test_dir]:\n",
        "    folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if raw_dir.exists():\n",
        "    for class_dir in raw_dir.iterdir():\n",
        "        if not class_dir.is_dir():\n",
        "            continue\n",
        "        images = list(class_dir.glob(\"*\"))\n",
        "        random.shuffle(images)\n",
        "        n = len(images)\n",
        "        n_train = int(0.7 * n)\n",
        "        n_val = int(0.2 * n)\n",
        "        splits = {\n",
        "            train_dir / class_dir.name: images[:n_train],\n",
        "            val_dir / class_dir.name: images[n_train:n_train + n_val],\n",
        "            test_dir / class_dir.name: images[n_train + n_val:],\n",
        "        }\n",
        "        for split_dir, split_imgs in splits.items():\n",
        "            split_dir.mkdir(parents=True, exist_ok=True)\n",
        "            for img_path in split_imgs:\n",
        "                shutil.copy(img_path, split_dir / img_path.name)\n",
        "    print(\"Hoàn thành chia tập dữ liệu.\")\n",
        "else:\n",
        "    print(\"Bỏ qua bước chia tập vì không tìm thấy data/raw.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Cấu hình và huấn luyện\n",
        "Sử dụng lớp `WasteTrainer` trong `src/training/trainer.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Khoi tao cau hinh huan luyen\n",
        "from pathlib import Path\n",
        "\n",
        "AVAILABLE_MODELS = [\"resnet18\", \"mobilenetv3\", \"efficientnetb0\"]\n",
        "\n",
        "MODEL_LIST = \"resnet18\"  #@param {type:\"string\"}\n",
        "EPOCHS = 15  #@param {type:\"integer\"}\n",
        "IMG_SIZE = 224  #@param {type:\"integer\"}\n",
        "BATCH_SIZE = 32  #@param {type:\"integer\"}\n",
        "NUM_WORKERS = 2  #@param {type:\"integer\"}\n",
        "LOSS = \"focal\"  #@param [\"cross_entropy\", \"focal\"]\n",
        "FOCAL_GAMMA = 2.0  #@param {type:\"number\"}\n",
        "OPTIM = \"adamw\"  #@param [\"adam\", \"adamw\", \"sgd\"]\n",
        "LR = 3e-4  #@param {type:\"number\"}\n",
        "WEIGHT_DECAY = 1e-4  #@param {type:\"number\"}\n",
        "SCHEDULER = \"onecycle\"  #@param [\"onecycle\", \"cosine\", \"step\", \"none\"]\n",
        "MAX_LR = 1e-3  #@param {type:\"number\"}\n",
        "DEVICE = \"cuda\"  #@param [\"cuda\", \"cpu\"]\n",
        "LOG_EVERY = 20  #@param {type:\"integer\"}\n",
        "FREEZE_BACKBONE_EPOCHS = 5  #@param {type:\"integer\"}\n",
        "OUTPUT_DIR = \"artifacts\"  #@param {type:\"string\"}\n",
        "SELECT_MODEL_METRIC = \"macro_f1\"  #@param [\"macro_f1\", \"accuracy\", \"macro_precision\", \"macro_recall\"]\n",
        "\n",
        "MODEL_NAMES = [name.strip().lower() for name in MODEL_LIST.split(\",\") if name.strip()]\n",
        "MODEL_NAMES = [name for name in MODEL_NAMES if name in AVAILABLE_MODELS]\n",
        "if not MODEL_NAMES:\n",
        "    MODEL_NAMES = [\"resnet18\"]\n",
        "    print(\"MODEL_LIST khong hop le, su dung mac dinh resnet18.\")\n",
        "\n",
        "from src.training.dataset import DataConfig\n",
        "from src.training.losses import LossConfig\n",
        "from src.training.optim import OptimConfig, SchedulerConfig\n",
        "from src.training.trainer import TrainConfig, WasteTrainer\n",
        "\n",
        "DATA_ROOT = globals().get('DATA_ROOT', '/content/TrashProject/data')\n",
        "data_cfg = DataConfig(\n",
        "    train_dir=Path(DATA_ROOT) / \"train\",\n",
        "    val_dir=Path(DATA_ROOT) / \"val\",\n",
        "    test_dir=Path(DATA_ROOT) / \"test\",\n",
        "    img_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        ")\n",
        "\n",
        "loss_cfg = LossConfig(name=LOSS, gamma=FOCAL_GAMMA) if LOSS == \"focal\" else LossConfig(name=LOSS)\n",
        "optim_cfg = OptimConfig(name=OPTIM, lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "scheduler_cfg = None\n",
        "if SCHEDULER != \"none\":\n",
        "    scheduler_cfg = SchedulerConfig(name=SCHEDULER, max_lr=MAX_LR)\n",
        "\n",
        "BASE_OUTPUT_DIR = Path(OUTPUT_DIR)\n",
        "BASE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "BASE_TRAIN_KWARGS = dict(\n",
        "    data=data_cfg,\n",
        "    loss=loss_cfg,\n",
        "    optim=optim_cfg,\n",
        "    scheduler=scheduler_cfg,\n",
        "    epochs=EPOCHS,\n",
        "    device=DEVICE,\n",
        "    log_every=LOG_EVERY,\n",
        "    freeze_backbone_epochs=FREEZE_BACKBONE_EPOCHS,\n",
        ")\n",
        "\n",
        "print(f\"Models: {MODEL_NAMES}\")\n",
        "print(f\"Epochs: {EPOCHS}, Batch size: {BATCH_SIZE}, LR: {LR}\")\n",
        "print(f\"Loss: {LOSS}, Scheduler: {SCHEDULER}, Freeze epochs: {FREEZE_BACKBONE_EPOCHS}\")\n",
        "print(f\"Artifacts root: {BASE_OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Huan luyen va so sanh mo hinh\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    import pandas as pd\n",
        "except ImportError as exc:\n",
        "    raise RuntimeError('Can install pandas trong moi truong notebook') from exc\n",
        "\n",
        "trained_models = {}\n",
        "results = []\n",
        "\n",
        "for model_name in MODEL_NAMES:\n",
        "    print(f\"===== Huan luyen {model_name} =====\")\n",
        "    cfg = TrainConfig(\n",
        "        model_name=model_name,\n",
        "        output_dir=BASE_OUTPUT_DIR / model_name,\n",
        "        **BASE_TRAIN_KWARGS,\n",
        "    )\n",
        "    trainer = WasteTrainer(cfg)\n",
        "    report, cm = trainer.train()\n",
        "    trained_models[model_name] = {\"trainer\": trainer, \"report\": report, \"cm\": cm}\n",
        "    if report:\n",
        "        macro = report.get(\"macro avg\", {})\n",
        "        results.append({\n",
        "            \"model\": model_name,\n",
        "            \"test_accuracy\": report.get(\"accuracy\"),\n",
        "            \"macro_precision\": macro.get(\"precision\"),\n",
        "            \"macro_recall\": macro.get(\"recall\"),\n",
        "            \"macro_f1\": macro.get(\"f1-score\"),\n",
        "        })\n",
        "    else:\n",
        "        results.append({\n",
        "            \"model\": model_name,\n",
        "            \"test_accuracy\": None,\n",
        "            \"macro_precision\": None,\n",
        "            \"macro_recall\": None,\n",
        "            \"macro_f1\": None,\n",
        "        })\n",
        "    print()\n",
        "\n",
        "MODEL_RESULTS_DF = None\n",
        "best_trainer = None\n",
        "best_report = None\n",
        "best_cm = None\n",
        "best_model_name = None\n",
        "\n",
        "if results:\n",
        "    MODEL_RESULTS_DF = pd.DataFrame(results).set_index(\"model\")\n",
        "    display(MODEL_RESULTS_DF)\n",
        "\n",
        "    metric_series = MODEL_RESULTS_DF[SELECT_MODEL_METRIC]\n",
        "    if metric_series.notna().any():\n",
        "        best_model_name = metric_series.astype(float).idxmax()\n",
        "    else:\n",
        "        best_model_name = MODEL_NAMES[0]\n",
        "        print(\"Khong co chi so hop le tren test, chon mo hinh dau tien.\")\n",
        "    print(f\"Chon mo hinh tot nhat: {best_model_name} (theo {SELECT_MODEL_METRIC})\")\n",
        "    best_info = trained_models[best_model_name]\n",
        "    best_trainer = best_info[\"trainer\"]\n",
        "    best_report = best_info[\"report\"]\n",
        "    best_cm = best_info[\"cm\"]\n",
        "else:\n",
        "    print(\"Khong co ket qua nao. Hay kiem tra data/raw.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0373cef-5237-439c-b0e3-20e0999afb34",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Bao cao chi tiet mo hinh tot nhat\n",
        "try:\n",
        "    import pandas as pd\n",
        "except ImportError as exc:\n",
        "    raise RuntimeError('Can install pandas trong moi truong notebook') from exc\n",
        "\n",
        "if 'best_report' in globals() and best_report:\n",
        "    report_df = pd.DataFrame(best_report).T\n",
        "    display(report_df)\n",
        "else:\n",
        "    print(\"Chua co ket qua nao. Hay chay cell huan luyen truoc.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Hien thi ma tran nham lan\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "\n",
        "if 'best_cm' in globals() and best_cm is not None:\n",
        "    cm_obj = best_cm\n",
        "    cm_np = cm_obj.numpy() if isinstance(cm_obj, torch.Tensor) else cm_obj\n",
        "    labels = list(best_trainer.idx_to_class.values()) if 'best_trainer' in globals() and best_trainer else []\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm_np, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "else:\n",
        "    print('Chua co ma tran nham lan. Hay chay cell huan luyen truoc.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Demo Gradio\n",
        "Tải trọng số tốt nhất và tạo UI đơn giản cho phép người dùng upload ảnh."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Khoi tao Gradio demo\n",
        "import gradio as gr\n",
        "import gradio_client.utils as gradio_utils\n",
        "\n",
        "if 'best_trainer' not in globals() or best_trainer is None:\n",
        "    raise RuntimeError('Chua co mo hinh huan luyen. Hay chay cell huan luyen truoc.')\n",
        "\n",
        "# Work around Gradio bug when additionalProperties=False produces a bool schema\n",
        "_original_json_schema_to_python_type = gradio_utils._json_schema_to_python_type\n",
        "\n",
        "def _safe_json_schema_to_python_type(schema, defs):\n",
        "    if isinstance(schema, bool):\n",
        "        return 'Any'\n",
        "    return _original_json_schema_to_python_type(schema, defs)\n",
        "\n",
        "gradio_utils._json_schema_to_python_type = _safe_json_schema_to_python_type\n",
        "\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "model = best_trainer.model\n",
        "checkpoint = torch.load(best_trainer.config.output_dir / 'best.pt', map_location=best_trainer.device)\n",
        "model.load_state_dict(checkpoint['model_state'])\n",
        "model.eval()\n",
        "\n",
        "preprocess = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "class_names = [best_trainer.idx_to_class[idx] for idx in sorted(best_trainer.idx_to_class)]\n",
        "\n",
        "def predict(image: Image.Image):\n",
        "    tensor = preprocess(image).unsqueeze(0).to(best_trainer.device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(tensor)\n",
        "        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
        "    return {class_names[i]: float(probs[i]) for i in range(len(class_names))}\n",
        "\n",
        "gr.Interface(fn=predict, inputs=gr.Image(type='pil'), outputs=gr.Label(num_top_classes=3)).launch(share=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Lưu kết quả và tải xuống\n",
        "- Lưu lại mô hình, báo cáo metrics vào Drive.\n",
        "- Đảm bảo cập nhật báo cáo đồ án với bảng kết quả và nhận xét."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. So sánh mô hình\n",
        "Sau khi chạy huấn luyện với các kiến trúc khác nhau, hãy đặt `OUTPUT_DIR` khác nhau cho mỗi lần (ví dụ `artifacts_resnet18`, `artifacts_mobilenet`).\n",
        "Cell dưới đây sẽ đọc các thư mục output đó, tổng hợp Accuracy/Macro F1 trên test và best val acc để bạn so sánh nhanh.\n",
        "Chỉnh sửa biến `EXPERIMENT_DIRS` theo danh sách mô hình bạn đã huấn luyện.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "#@title Tổng hợp kết quả các mô hình đã huấn luyện\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "EXPERIMENT_DIRS = {\n",
        "    \"resnet18\": \"/content/TrashProject/artifacts_resnet18\",\n",
        "    \"mobilenetv3\": \"/content/TrashProject/artifacts_mobilenetv3\",\n",
        "    \"efficientnetb0\": \"/content/TrashProject/artifacts_efficientnetb0\",\n",
        "}  # Chỉnh sửa theo các output_dir bạn đã dùng\n",
        "\n",
        "summary = []\n",
        "for name, dir_path in EXPERIMENT_DIRS.items():\n",
        "    dir_path = Path(dir_path)\n",
        "    if not dir_path.exists():\n",
        "        print(f\"[WARN] {dir_path} không tồn tại, bỏ qua.\")\n",
        "        continue\n",
        "    report_path = dir_path / \"classification_report.pth\"\n",
        "    history_path = dir_path / \"history.pth\"\n",
        "    macro_f1 = accuracy = best_val_acc = None\n",
        "\n",
        "    if report_path.exists():\n",
        "        report = torch.load(report_path)\n",
        "        macro_f1 = report.get(\"macro avg\", {}).get(\"f1-score\")\n",
        "        accuracy = report.get(\"accuracy\")\n",
        "    if history_path.exists():\n",
        "        history = torch.load(history_path)\n",
        "        if isinstance(history, dict) and \"val_acc\" in history:\n",
        "            best_val_acc = max(history[\"val_acc\"])\n",
        "\n",
        "    summary.append({\n",
        "        \"model\": name,\n",
        "        \"output_dir\": str(dir_path),\n",
        "        \"test_accuracy\": accuracy,\n",
        "        \"test_macro_f1\": macro_f1,\n",
        "        \"best_val_acc\": best_val_acc,\n",
        "    })\n",
        "\n",
        "if not summary:\n",
        "    print(\"Chưa có kết quả nào. Hãy chạy huấn luyện và lưu output_dir riêng cho từng mô hình.\")\n",
        "else:\n",
        "    header = (\"Model\", \"Output Dir\", \"Test Acc\", \"Test Macro F1\", \"Best Val Acc\")\n",
        "    row_fmt = \"{:<15} {:<40} {:>11} {:>15} {:>13}\"\n",
        "    print(row_fmt.format(*header))\n",
        "    print('-' * 96)\n",
        "    for row in summary:\n",
        "        print(row_fmt.format(\n",
        "            row[\"model\"],\n",
        "            row[\"output_dir\"],\n",
        "            f\"{row['test_accuracy']:.3f}\" if row[\"test_accuracy\"] is not None else \"n/a\",\n",
        "            f\"{row['test_macro_f1']:.3f}\" if row[\"test_macro_f1\"] is not None else \"n/a\",\n",
        "            f\"{row['best_val_acc']:.3f}\" if row[\"best_val_acc\"] is not None else \"n/a\",\n",
        "        ))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}