{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d9272d0",
   "metadata": {},
   "source": [
    "# Waste Classification Training (Colab Ready)\n",
    "\n",
    "Notebook này hướng dẫn toàn bộ pipeline: chuẩn bị dữ liệu, huấn luyện mô hình CNN/Transfer Learning, đánh giá và tạo demo Gradio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0daaca1",
   "metadata": {},
   "source": [
    "## 1. Thiết lập môi trường\n",
    "- Chạy trên GPU (Runtime → Change runtime type → GPU)\n",
    "- Kết nối Google Drive nếu dữ liệu/model lưu trên đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8270cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Mount Google Drive (tùy chọn)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a0551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Cài đặt phụ thuộc\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -q albumentations==1.4.7 timm==1.0.3 grad-cam==1.5.5 gradio==4.44.0 scikit-learn==1.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532655fc",
   "metadata": {
    "cellView": "form",
    "id": "d57b9bd5-ae5f-495f-892f-581258371c44"
   },
   "outputs": [],
   "source": [
    "#@title Kiem tra tai nguyen Colab\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    import psutil\n",
    "except ImportError:\n",
    "    psutil = None\n",
    "\n",
    "print(\"Tinh trang tai nguyen:\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"- GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"- GPU: chua bat. Vao Runtime > Change runtime type > GPU.\")\n",
    "\n",
    "total, used, free = shutil.disk_usage(\"/\")\n",
    "print(f\"- O dia: {total/1e9:.1f} GB tong | {free/1e9:.1f} GB trong\")\n",
    "\n",
    "if psutil is not None:\n",
    "    ram = psutil.virtual_memory()\n",
    "    print(f\"- RAM: {ram.total/1e9:.1f} GB tong | {ram.available/1e9:.1f} GB kha dung\")\n",
    "else:\n",
    "    print(\"- RAM: cai psutil de hien thi (pip install psutil)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb4a499",
   "metadata": {},
   "source": [
    "## 2. Chuẩn bị dự án\n",
    "- Nếu đã upload project lên GitHub, clone trực tiếp.\n",
    "- Nếu làm việc trên Drive, unzip project vào `/content/TrashProject`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdc7941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Clone hoặc đồng bộ mã nguồn\n",
    "import os, shutil, zipfile, sys\n",
    "\n",
    "PROJECT_PATH = \"/content/TrashProject\"  # chỉnh sửa nếu cần\n",
    "GIT_REPO_URL = \"https://github.com/tuanng007/TrashProject.git\"\n",
    "\n",
    "if not os.path.exists(PROJECT_PATH):\n",
    "    !git clone $GIT_REPO_URL $PROJECT_PATH\n",
    "else:\n",
    "    print(f\"Su dung thu muc co san: {PROJECT_PATH}\")\n",
    "\n",
    "sys.path.append(PROJECT_PATH)\n",
    "os.chdir(PROJECT_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c43ced7",
   "metadata": {},
   "source": [
    "## 3. Tải và tiền xử lý dữ liệu\n",
    "- Có thể dùng script sẵn có để tải TrashNet về thư mục data/raw.\n",
    "- Hoặc dùng dataset công khai khác/Kaggle ở các cell tiếp theo.\n",
    "- Có thể thay bằng dataset tự thu thập (đưa vào thư mục data/raw).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78abbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Tải TrashNet từ GitHub\n",
    "import os\n",
    "DOWNLOAD_TRASHNET = True  #@param {type:\"boolean\"}\n",
    "DATA_ROOT = \"/content/TrashProject/data\"  #@param {type:\"string\"}\n",
    "RAW_DATA_DIR = f\"{DATA_ROOT}/raw\"\n",
    "os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
    "if DOWNLOAD_TRASHNET:\n",
    "    !python scripts/download_trashnet.py --output-dir {RAW_DATA_DIR}\n",
    "    print(\"TrashNet downloaded.\")\n",
    "print(f\"Raw data folder: {RAW_DATA_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ef0316",
   "metadata": {},
   "source": [
    "## 3.1 Khám phá dữ liệu tổng quan (EDA trên raw)\n",
    "\n",
    "- Thống kê phân bố số mẫu theo lớp trên `data/raw` trước khi chia train/val/test.\n",
    "- Hiển thị một vài ảnh mẫu từ raw để kiểm tra nhanh chất lượng dữ liệu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118cdbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title EDA tổng quan trên raw (phân bố lớp)\n",
    "from pathlib import Path\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "DATA_ROOT = globals().get('DATA_ROOT', '/content/TrashProject/data')\n",
    "raw_dir = Path(DATA_ROOT) / 'raw'\n",
    "\n",
    "if not raw_dir.exists():\n",
    "    print(f'Khong tim thay thu muc raw: {raw_dir}')\n",
    "else:\n",
    "    class_counts = {}\n",
    "    for class_dir in sorted(raw_dir.iterdir()):\n",
    "        if class_dir.is_dir():\n",
    "            class_counts[class_dir.name] = len(list(class_dir.glob('*')))\n",
    "\n",
    "    print('So mau theo lop (raw):')\n",
    "    for cls, n in class_counts.items():\n",
    "        print(f'  {cls}: {n}')\n",
    "    print('\\nTong so mau:', sum(class_counts.values()))\n",
    "\n",
    "    if class_counts:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.barplot(x=list(class_counts.keys()), y=list(class_counts.values()))\n",
    "        plt.title('Phan bo so mau theo lop (raw)')\n",
    "        plt.ylabel('So anh')\n",
    "        plt.xticks(rotation=30)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Hien thi mot vai anh mau tu raw\n",
    "    sample_paths = []\n",
    "    for cls, n in class_counts.items():\n",
    "        class_dir = raw_dir / cls\n",
    "        imgs = list(class_dir.glob('*'))\n",
    "        if imgs:\n",
    "            sample_paths.extend(random.sample(imgs, min(2, len(imgs))))\n",
    "\n",
    "    if sample_paths:\n",
    "        cols = 4\n",
    "        rows = (len(sample_paths) + cols - 1) // cols\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 3 * rows))\n",
    "        axes = axes.flatten()\n",
    "        for ax, img_path in zip(axes, sample_paths):\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                ax.imshow(img)\n",
    "                ax.set_title(img_path.parent.name)\n",
    "                ax.axis('off')\n",
    "            except Exception:\n",
    "                ax.set_title(f'Loi doc anh: {img_path.name}')\n",
    "                ax.axis('off')\n",
    "        for ax in axes[len(sample_paths):]:\n",
    "            ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('Khong tim thay anh trong data/raw.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ff870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title T?o train/val/test split (70/20/10)\n",
    "DATA_ROOT = globals().get('DATA_ROOT', '/content/TrashProject/data')\n",
    "SPLIT_SEED = 42  #@param {type:\"integer\"}\n",
    "from pathlib import Path\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "raw_dir = Path(DATA_ROOT) / \"raw\"\n",
    "train_dir = Path(DATA_ROOT) / \"train\"\n",
    "val_dir = Path(DATA_ROOT) / \"val\"\n",
    "test_dir = Path(DATA_ROOT) / \"test\"\n",
    "\n",
    "IMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\"}\n",
    "rng = random.Random(SPLIT_SEED)\n",
    "\n",
    "for folder in [train_dir, val_dir, test_dir]:\n",
    "    if folder.exists():\n",
    "        shutil.rmtree(folder)\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if raw_dir.exists():\n",
    "    for class_dir in sorted(raw_dir.iterdir()):\n",
    "        if not class_dir.is_dir():\n",
    "            continue\n",
    "        images = [p for p in class_dir.glob('*') if p.suffix.lower() in IMAGE_EXTS]\n",
    "\n",
    "        if not images:\n",
    "            continue\n",
    "        rng.shuffle(images)\n",
    "        n = len(images)\n",
    "        n_train = int(0.7 * n)\n",
    "        n_val = int(0.2 * n)\n",
    "        splits = {\n",
    "            train_dir / class_dir.name: images[:n_train],\n",
    "            val_dir / class_dir.name: images[n_train:n_train + n_val],\n",
    "            test_dir / class_dir.name: images[n_train + n_val:],\n",
    "        }\n",
    "        for split_dir, split_imgs in splits.items():\n",
    "            split_dir.mkdir(parents=True, exist_ok=True)\n",
    "            for img_path in split_imgs:\n",
    "                shutil.copy(img_path, split_dir / img_path.name)\n",
    "    print(\"Ho?n th?nh chia t?p d? li?u.\")\n",
    "else:\n",
    "    print(\"B? qua b??c chia t?p v? kh?ng t?m th?y data/raw.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b7a9e9",
   "metadata": {},
   "source": [
    "## 3.1 Khám phá dữ liệu (EDA)\n",
    "\n",
    "- Thống kê phân bố số mẫu theo lớp sau khi chia train/val/test.\n",
    "- Hiển thị một vài ảnh mẫu để kiểm tra nhanh chất lượng dữ liệu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873104c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title EDA nhanh: phân bố lớp & một vài ảnh mẫu\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "DATA_ROOT = globals().get('DATA_ROOT', '/content/TrashProject/data')\n",
    "train_dir = Path(DATA_ROOT) / 'train'\n",
    "val_dir = Path(DATA_ROOT) / 'val'\n",
    "test_dir = Path(DATA_ROOT) / 'test'\n",
    "\n",
    "def count_images(root: Path):\n",
    "    counts = {}\n",
    "    if root.exists():\n",
    "        for class_dir in sorted(root.iterdir()):\n",
    "            if class_dir.is_dir():\n",
    "                counts[class_dir.name] = len(list(class_dir.glob('*')))\n",
    "    return counts\n",
    "\n",
    "train_counts = count_images(train_dir)\n",
    "val_counts = count_images(val_dir)\n",
    "test_counts = count_images(test_dir)\n",
    "\n",
    "print('Số mẫu theo lớp (train):')\n",
    "for cls, n in train_counts.items():\n",
    "    print(f'  {cls}: {n}')\n",
    "print('\\nTổng số mẫu train:', sum(train_counts.values()))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=list(train_counts.keys()), y=list(train_counts.values()))\n",
    "plt.title('Phân bố số mẫu theo lớp (train)')\n",
    "plt.ylabel('Số ảnh')\n",
    "plt.xticks(rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Hiển thị một vài ảnh mẫu từ train\n",
    "sample_paths = []\n",
    "for cls, n in train_counts.items():\n",
    "    class_dir = train_dir / cls\n",
    "    imgs = list(class_dir.glob('*'))\n",
    "    sample_paths.extend(random.sample(imgs, min(2, len(imgs))))\n",
    "\n",
    "if sample_paths:\n",
    "    cols = 4\n",
    "    rows = (len(sample_paths) + cols - 1) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 3*rows))\n",
    "    axes = axes.flatten()\n",
    "    for ax, img_path in zip(axes, sample_paths):\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(img_path.parent.name)\n",
    "            ax.axis('off')\n",
    "        except Exception as exc:  # noqa: BLE001\n",
    "            ax.set_title(f'Lỗi đọc ảnh: {img_path.name}')\n",
    "            ax.axis('off')\n",
    "    for ax in axes[len(sample_paths):]:\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Không tìm thấy ảnh trong thư mục train.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c0bb0e",
   "metadata": {},
   "source": [
    "## 4. Cấu hình và huấn luyện\n",
    "Sử dụng lớp `WasteTrainer` trong `src/training/trainer.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d772ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Khoi tao cau hinh huan luyen\n",
    "from pathlib import Path\n",
    "\n",
    "AVAILABLE_MODELS = [\"resnet18\", \"mobilenetv3\", \"efficientnetb0\", \"vitb16\"]\n",
    "\n",
    "MODEL_LIST = \"resnet18\"  #@param {type:\"string\"}\n",
    "EPOCHS = 15  #@param {type:\"integer\"}\n",
    "IMG_SIZE = 224  #@param {type:\"integer\"}\n",
    "BATCH_SIZE = 32  #@param {type:\"integer\"}\n",
    "NUM_WORKERS = 2  #@param {type:\"integer\"}\n",
    "LOSS = \"focal\"  #@param [\"cross_entropy\", \"focal\"]\n",
    "FOCAL_GAMMA = 2.0  #@param {type:\"number\"}\n",
    "USE_BLUR = False  #@param {type:\"boolean\"}\n",
    "USE_RANDOM_ERASING = False  #@param {type:\"boolean\"}\n",
    "USE_MIXUP = False  #@param {type:\"boolean\"}\n",
    "USE_CUTMIX = False  #@param {type:\"boolean\"}\n",
    "MIXUP_ALPHA = 0.4  #@param {type:\"number\"}\n",
    "CUTMIX_ALPHA = 1.0  #@param {type:\"number\"}\n",
    "OPTIM = \"adamw\"  #@param [\"adam\", \"adamw\", \"sgd\"]\n",
    "LR = 3e-4  #@param {type:\"number\"}\n",
    "WEIGHT_DECAY = 1e-4  #@param {type:\"number\"}\n",
    "SCHEDULER = \"onecycle\"  #@param [\"onecycle\", \"cosine\", \"step\", \"none\"]\n",
    "MAX_LR = 1e-3  #@param {type:\"number\"}\n",
    "DEVICE = \"cuda\"  #@param [\"cuda\", \"cpu\"]\n",
    "LOG_EVERY = 20  #@param {type:\"integer\"}\n",
    "FREEZE_BACKBONE_EPOCHS = 5  #@param {type:\"integer\"}\n",
    "OUTPUT_DIR = \"artifacts\"  #@param {type:\"string\"}\n",
    "EARLY_STOP_PATIENCE = 3  #@param {type:\"integer\"}\n",
    "EARLY_STOP_MIN_DELTA = 0.002  #@param {type:\"number\"}\n",
    "SELECT_MODEL_METRIC = \"macro_f1\"  #@param [\"macro_f1\", \"accuracy\", \"macro_precision\", \"macro_recall\"]\n",
    "\n",
    "MODEL_NAMES = [name.strip().lower() for name in MODEL_LIST.split(\",\") if name.strip()]\n",
    "MODEL_NAMES = [name for name in MODEL_NAMES if name in AVAILABLE_MODELS]\n",
    "if not MODEL_NAMES:\n",
    "    MODEL_NAMES = [\"resnet18\"]\n",
    "    print(\"MODEL_LIST khong hop le, su dung mac dinh resnet18.\")\n",
    "\n",
    "from src.training.dataset import DataConfig\n",
    "from src.training.losses import LossConfig\n",
    "from src.training.optim import OptimConfig, SchedulerConfig\n",
    "from src.training.trainer import TrainConfig, WasteTrainer\n",
    "\n",
    "DATA_ROOT = globals().get('DATA_ROOT', '/content/TrashProject/data')\n",
    "data_cfg = DataConfig(\n",
    "    train_dir=Path(DATA_ROOT) / \"train\",\n",
    "    val_dir=Path(DATA_ROOT) / \"val\",\n",
    "    test_dir=Path(DATA_ROOT) / \"test\",\n",
    "    img_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    use_blur=USE_BLUR,\n",
    "    use_random_erasing=USE_RANDOM_ERASING,\n",
    ")\n",
    "\n",
    "loss_cfg = LossConfig(name=LOSS, gamma=FOCAL_GAMMA) if LOSS == \"focal\" else LossConfig(name=LOSS)\n",
    "optim_cfg = OptimConfig(name=OPTIM, lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler_cfg = None\n",
    "if SCHEDULER != \"none\":\n",
    "    scheduler_cfg = SchedulerConfig(name=SCHEDULER, max_lr=MAX_LR)\n",
    "\n",
    "BASE_OUTPUT_DIR = Path(OUTPUT_DIR)\n",
    "BASE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BASE_TRAIN_KWARGS = dict(\n",
    "    data=data_cfg,\n",
    "    loss=loss_cfg,\n",
    "    optim=optim_cfg,\n",
    "    scheduler=scheduler_cfg,\n",
    "    epochs=EPOCHS,\n",
    "    device=DEVICE,\n",
    "    log_every=LOG_EVERY,\n",
    "    freeze_backbone_epochs=FREEZE_BACKBONE_EPOCHS,\n",
    "    use_mixup=USE_MIXUP,\n",
    "    use_cutmix=USE_CUTMIX,\n",
    "    mixup_alpha=MIXUP_ALPHA,\n",
    "    cutmix_alpha=CUTMIX_ALPHA,\n",
    "    early_stop_patience=EARLY_STOP_PATIENCE,\n",
    "    early_stop_min_delta=EARLY_STOP_MIN_DELTA,\n",
    ")\n",
    "\n",
    "print(f\"Models: {MODEL_NAMES}\")\n",
    "print(f\"Epochs: {EPOCHS}, Batch size: {BATCH_SIZE}, LR: {LR}\")\n",
    "print(f\"Loss: {LOSS}, Scheduler: {SCHEDULER}, Freeze epochs: {FREEZE_BACKBONE_EPOCHS}\")\n",
    "print(f\"Artifacts root: {BASE_OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271e7bb5",
   "metadata": {},
   "source": [
    "### 4.1 Minh hoạ ảnh sau resize & augmentation\n",
    "\n",
    "- Cell dưới đây giúp trực quan hoá ảnh gốc, ảnh sau resize/crop và các phiên bản sau data augmentation.\n",
    "- Dùng trực tiếp pipeline trong `src/training/dataset.py` để đảm bảo giống hệt khi huấn luyện.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818ef8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Vi du minh hoa augmentation (train transforms, blur, erasing, mixup, cutmix)\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from src.training.dataset import WasteDataset, default_transforms\n",
    "\n",
    "DATA_ROOT = globals().get('DATA_ROOT', '/content/TrashProject/data')\n",
    "IMG_SIZE = globals().get('IMG_SIZE', 224)\n",
    "\n",
    "# Lay transforms giong training (co tinh den blur, random erasing)\n",
    "USE_BLUR = globals().get('USE_BLUR', False)\n",
    "USE_RANDOM_ERASING = globals().get('USE_RANDOM_ERASING', False)\n",
    "train_tf, eval_tf, _ = default_transforms(\n",
    "    IMG_SIZE,\n",
    "    use_blur=USE_BLUR,\n",
    "    use_random_erasing=USE_RANDOM_ERASING,\n",
    ")\n",
    "raw_ds = WasteDataset(Path(DATA_ROOT) / 'train', transform=None)\n",
    "\n",
    "# Lay mot anh goc\n",
    "pil_img, _ = raw_ds[0]\n",
    "\n",
    "# Hien thi anh goc vs sau resize/crop (eval transform)\n",
    "eval_tensor = eval_tf(pil_img)\n",
    "mean = torch.tensor([0.485, 0.456, 0.406])[:, None, None]\n",
    "std = torch.tensor([0.229, 0.224, 0.225])[:, None, None]\n",
    "eval_vis = (eval_tensor * std + mean).clamp(0, 1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "axes[0].imshow(pil_img)\n",
    "axes[0].set_title('Anh goc (raw)')\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(eval_vis.permute(1, 2, 0).cpu().numpy())\n",
    "axes[1].set_title('Sau resize/crop (eval_tf)')\n",
    "axes[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tao nhieu phien ban augmentation tu cung mot anh (train_tf)\n",
    "imgs = []\n",
    "for _ in range(6):\n",
    "    t = train_tf(pil_img)\n",
    "    t = (t * std + mean).clamp(0, 1)\n",
    "    imgs.append(t)\n",
    "\n",
    "grid = make_grid(torch.stack(imgs), nrow=6)\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
    "plt.axis('off')\n",
    "plt.title('Cung mot anh sau cac lan augmentation khac nhau (train transforms)')\n",
    "plt.show()\n",
    "\n",
    "# Minh hoa mixup / cutmix tren batch nho (neu dang bat trong config)\n",
    "USE_MIXUP = globals().get('USE_MIXUP', False)\n",
    "USE_CUTMIX = globals().get('USE_CUTMIX', False)\n",
    "if USE_MIXUP or USE_CUTMIX:\n",
    "    # Tao batch 4 anh da duoc train_tf (co blur / erasing neu bat)\n",
    "    batch_imgs = []\n",
    "    for _ in range(4):\n",
    "        t = train_tf(pil_img)\n",
    "        batch_imgs.append(t)\n",
    "    batch = torch.stack(batch_imgs)\n",
    "\n",
    "    mixed_list = []\n",
    "    if USE_MIXUP:\n",
    "        alpha = float(globals().get('MIXUP_ALPHA', 0.4))\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "        idx = torch.randperm(batch.size(0))\n",
    "        mixed = lam * batch + (1 - lam) * batch[idx]\n",
    "        mixed_list.append(mixed)\n",
    "\n",
    "    if USE_CUTMIX:\n",
    "        alpha = float(globals().get('CUTMIX_ALPHA', 1.0))\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "        b, c, h, w = batch.size()\n",
    "        cx = np.random.randint(w)\n",
    "        cy = np.random.randint(h)\n",
    "        cut_w = int(w * (1 - lam) ** 0.5)\n",
    "        cut_h = int(h * (1 - lam) ** 0.5)\n",
    "        x0 = max(cx - cut_w // 2, 0)\n",
    "        y0 = max(cy - cut_h // 2, 0)\n",
    "        x1 = min(cx + cut_w // 2, w)\n",
    "        y1 = min(cy + cut_h // 2, h)\n",
    "        idx = torch.randperm(b)\n",
    "        cut = batch.clone()\n",
    "        cut[:, :, y0:y1, x0:x1] = batch[idx, :, y0:y1, x0:x1]\n",
    "        mixed_list.append(cut)\n",
    "\n",
    "    if mixed_list:\n",
    "        vis = []\n",
    "        for img_t in mixed_list[0]:\n",
    "            img_vis = (img_t * std + mean).clamp(0, 1)\n",
    "            vis.append(img_vis)\n",
    "        grid2 = make_grid(torch.stack(vis), nrow=len(vis))\n",
    "        plt.figure(figsize=(8, 3))\n",
    "        plt.imshow(grid2.permute(1, 2, 0).cpu().numpy())\n",
    "        plt.axis('off')\n",
    "        if USE_MIXUP and USE_CUTMIX:\n",
    "            title = 'Batch sau mixup + cutmix'\n",
    "        elif USE_MIXUP:\n",
    "            title = 'Batch sau mixup'\n",
    "        else:\n",
    "            title = 'Batch sau cutmix'\n",
    "        plt.title(title)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e410ac",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Huan luyen va so sanh mo hinh\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError as exc:\n",
    "    raise RuntimeError('Can install pandas trong moi truong notebook') from exc\n",
    "\n",
    "trained_models = {}\n",
    "results = []\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(f\"===== Huan luyen {model_name} =====\")\n",
    "    cfg = TrainConfig(\n",
    "        model_name=model_name,\n",
    "        output_dir=BASE_OUTPUT_DIR / model_name,\n",
    "        **BASE_TRAIN_KWARGS,\n",
    "    )\n",
    "    trainer = WasteTrainer(cfg)\n",
    "    report, cm = trainer.train()\n",
    "    trained_models[model_name] = {\"trainer\": trainer, \"report\": report, \"cm\": cm}\n",
    "    if report:\n",
    "        macro = report.get(\"macro avg\", {})\n",
    "        results.append({\n",
    "            \"model\": model_name,\n",
    "            \"test_accuracy\": report.get(\"accuracy\"),\n",
    "            \"macro_precision\": macro.get(\"precision\"),\n",
    "            \"macro_recall\": macro.get(\"recall\"),\n",
    "            \"macro_f1\": macro.get(\"f1-score\"),\n",
    "        })\n",
    "    else:\n",
    "        results.append({\n",
    "            \"model\": model_name,\n",
    "            \"test_accuracy\": None,\n",
    "            \"macro_precision\": None,\n",
    "            \"macro_recall\": None,\n",
    "            \"macro_f1\": None,\n",
    "        })\n",
    "    print()\n",
    "\n",
    "MODEL_RESULTS_DF = None\n",
    "best_trainer = None\n",
    "best_report = None\n",
    "best_cm = None\n",
    "best_model_name = None\n",
    "\n",
    "if results:\n",
    "    MODEL_RESULTS_DF = pd.DataFrame(results).set_index(\"model\")\n",
    "    display(MODEL_RESULTS_DF)\n",
    "\n",
    "    metric_series = MODEL_RESULTS_DF[SELECT_MODEL_METRIC]\n",
    "    if metric_series.notna().any():\n",
    "        best_model_name = metric_series.astype(float).idxmax()\n",
    "    else:\n",
    "        best_model_name = MODEL_NAMES[0]\n",
    "        print(\"Khong co chi so hop le tren test, chon mo hinh dau tien.\")\n",
    "    print(f\"Chon mo hinh tot nhat: {best_model_name} (theo {SELECT_MODEL_METRIC})\")\n",
    "    best_info = trained_models[best_model_name]\n",
    "    best_trainer = best_info[\"trainer\"]\n",
    "    best_report = best_info[\"report\"]\n",
    "    best_cm = best_info[\"cm\"]\n",
    "else:\n",
    "    print(\"Khong co ket qua nao. Hay kiem tra data/raw.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6ef541",
   "metadata": {},
   "source": [
    "### 4.2 Biểu đồ huấn luyện (loss & accuracy)\n",
    "\n",
    "- Cell dưới đây vẽ lại loss/accuracy theo epoch từ file `history.pth` của mô hình đã huấn luyện.\n",
    "- Có thể chọn tên mô hình trùng với `MODEL_LIST`/`MODEL_NAMES` (ví dụ: `resnet18`, `mobilenetv3`, `efficientnetb0`, `vitb16`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943d75a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Bieu do loss & accuracy theo epoch\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PLOT_MODEL = \"efficientnetb0\"  #@param {type:\"string\"}\n",
    "\n",
    "BASE_OUTPUT_DIR = globals().get('BASE_OUTPUT_DIR', Path('artifacts'))\n",
    "exp_dir = BASE_OUTPUT_DIR / PLOT_MODEL\n",
    "history_path = exp_dir / 'history.pth'\n",
    "\n",
    "print(f\"Doc history tu: {history_path}\")\n",
    "if not history_path.exists():\n",
    "    print(\"Khong tim thay history.pth. Hay chac chan da train va OUTPUT_DIR dung.\")\n",
    "else:\n",
    "    history = torch.load(history_path)\n",
    "    if not isinstance(history, dict) or 'train_loss' not in history:\n",
    "        print(\"Dinh dang history khong hop le.\")\n",
    "    else:\n",
    "        epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, history['train_loss'], label='Train loss')\n",
    "        plt.plot(epochs, history['val_loss'], label='Val loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(f'Loss - {PLOT_MODEL}')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, history['val_acc'], label='Val accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title(f'Val accuracy - {PLOT_MODEL}')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b782d10e",
   "metadata": {
    "cellView": "form",
    "id": "a0373cef-5237-439c-b0e3-20e0999afb34"
   },
   "outputs": [],
   "source": [
    "#@title Bao cao chi tiet mo hinh tot nhat\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError as exc:\n",
    "    raise RuntimeError('Can install pandas trong moi truong notebook') from exc\n",
    "\n",
    "if 'best_report' in globals() and best_report:\n",
    "    report_df = pd.DataFrame(best_report).T\n",
    "    display(report_df)\n",
    "else:\n",
    "    print(\"Chua co ket qua nao. Hay chay cell huan luyen truoc.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d175df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Hien thi ma tran nham lan\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "if 'best_cm' in globals() and best_cm is not None:\n",
    "    cm_obj = best_cm\n",
    "    cm_np = cm_obj.numpy() if isinstance(cm_obj, torch.Tensor) else cm_obj\n",
    "    labels = list(best_trainer.idx_to_class.values()) if 'best_trainer' in globals() and best_trainer else []\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_np, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Chua co ma tran nham lan. Hay chay cell huan luyen truoc.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44445dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Phan tich loi: hien thi mot so mau du doan sai\n",
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "if 'best_trainer' not in globals() or best_trainer is None:\n",
    "    print('Chua co mo hinh tot nhat. Hay chay cell huan luyen truoc.')\n",
    "else:\n",
    "    device = best_trainer.device\n",
    "    model = best_trainer.model.eval()\n",
    "    loader = best_trainer.test_loader or best_trainer.val_loader\n",
    "    if loader is None:\n",
    "        print('Khong co test/val loader de phan tich.')\n",
    "    else:\n",
    "        dataset = loader.dataset\n",
    "        wrong_samples = []\n",
    "        with torch.no_grad():\n",
    "            for idx in range(len(dataset)):\n",
    "                img_tensor, label = dataset[idx]\n",
    "                logits = model(img_tensor.unsqueeze(0).to(device))\n",
    "                pred = int(torch.argmax(logits, dim=1).item())\n",
    "                if pred != int(label):\n",
    "                    img_path, _ = dataset.samples[idx]\n",
    "                    wrong_samples.append((img_path, int(label), pred))\n",
    "\n",
    "        if not wrong_samples:\n",
    "            print('Khong tim thay mau du doan sai tren loader nay.')\n",
    "        else:\n",
    "            n_show = min(8, len(wrong_samples))\n",
    "            samples_to_show = random.sample(wrong_samples, n_show)\n",
    "            cols = 4\n",
    "            rows = (n_show + cols - 1) // cols\n",
    "            fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 3*rows))\n",
    "            axes = axes.flatten()\n",
    "            for ax, (img_path, label, pred) in zip(axes, samples_to_show):\n",
    "                try:\n",
    "                    img = Image.open(img_path).convert('RGB')\n",
    "                    ax.imshow(img)\n",
    "                    true_name = best_trainer.idx_to_class[label]\n",
    "                    pred_name = best_trainer.idx_to_class[pred]\n",
    "                    ax.set_title(f'T:{true_name} / P:{pred_name}')\n",
    "                    ax.axis('off')\n",
    "                except Exception as exc:  # noqa: BLE001\n",
    "                    ax.set_title(f'Loi doc anh: {Path(img_path).name}')\n",
    "                    ax.axis('off')\n",
    "            for ax in axes[n_show:]:\n",
    "                ax.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8869851",
   "metadata": {},
   "source": [
    "## 5. Demo Gradio\n",
    "Tải trọng số tốt nhất và tạo UI đơn giản cho phép người dùng upload ảnh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658c3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Khoi tao Gradio demo (chon model + icon + top 6)\n",
    "import gradio as gr\n",
    "import gradio_client.utils as gradio_utils\n",
    "\n",
    "if 'trained_models' not in globals() or not trained_models:\n",
    "    raise RuntimeError('Chua co danh sach mo hinh. Hay chay cell \"Huan luyen va so sanh mo hinh\" truoc.')\n",
    "\n",
    "# Work around Gradio bug when additionalProperties=False produces a bool schema\n",
    "_original_json_schema_to_python_type = gradio_utils._json_schema_to_python_type\n",
    "\n",
    "def _safe_json_schema_to_python_type(schema, defs):\n",
    "    if isinstance(schema, bool):\n",
    "        return 'Any'\n",
    "    return _original_json_schema_to_python_type(schema, defs)\n",
    "\n",
    "gradio_utils._json_schema_to_python_type = _safe_json_schema_to_python_type\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "CLASS_ICONS = {\n",
    "    \"cardboard\": \"\\U0001F4E6\",  # icon cardboard\n",
    "    \"glass\": \"\\U0001F37E\",      # icon glass bottle\n",
    "    \"metal\": \"\\U0001F96B\",      # icon metal can\n",
    "    \"paper\": \"\\U0001F4C4\",      # icon paper\n",
    "    \"plastic\": \"\\U0001F9F4\",    # icon plastic bottle\n",
    "    \"trash\": \"\\U0001F5D1\",      # icon trash bin\n",
    "}\n",
    "\n",
    "# Load lai mo hinh tu trained_models\n",
    "model_names = sorted(trained_models.keys())\n",
    "loaded_models = {}\n",
    "\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "for name in model_names:\n",
    "    info = trained_models[name]\n",
    "    trainer = info['trainer']\n",
    "    model = trainer.model\n",
    "    ckpt_path = trainer.config.output_dir / 'best.pt'\n",
    "    state = torch.load(ckpt_path, map_location=trainer.device)\n",
    "    if isinstance(state, dict) and 'model_state' in state:\n",
    "        model.load_state_dict(state['model_state'])\n",
    "    else:\n",
    "        model.load_state_dict(state)\n",
    "    model.eval()\n",
    "    class_names = [trainer.idx_to_class[idx] for idx in sorted(trainer.idx_to_class)]\n",
    "    loaded_models[name] = {\n",
    "        'model': model,\n",
    "        'device': trainer.device,\n",
    "        'class_names': class_names,\n",
    "    }\n",
    "\n",
    "\n",
    "def predict(image: Image.Image, model_name: str):\n",
    "    if image is None:\n",
    "        return {}\n",
    "    info = loaded_models[model_name]\n",
    "    model = info['model']\n",
    "    device = info['device']\n",
    "    class_names = info['class_names']\n",
    "    tensor = preprocess(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(tensor)\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "\n",
    "    scores = {}\n",
    "    for i, name in enumerate(class_names):\n",
    "        icon = CLASS_ICONS.get(name, '')\n",
    "        label = f\"{icon} {name}\" if icon else name\n",
    "        scores[label] = float(probs[i])\n",
    "    return scores\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=[\n",
    "        gr.Image(type='pil', label='Upload anh rac'),\n",
    "        gr.Dropdown(choices=model_names, value=model_names[0], label='Chon mo hinh'),\n",
    "    ],\n",
    "    outputs=gr.Label(num_top_classes=6, label='Du doan loai rac (top 6)'),\n",
    "    title='Phan loai rac - So sanh mo hinh',\n",
    "    description=(\n",
    "        'Upload anh rac (chai nhua, giay, kim loai, thuy tinh, cardboard, trash...) '\n",
    "        'de chon va so sanh cac mo hinh (ResNet18, MobileNetV3, EfficientNetB0, ViT...) tren cung mot anh.'\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebb4845",
   "metadata": {},
   "source": [
    "## 6. Lưu kết quả và tải xuống\n",
    "- Lưu lại mô hình, báo cáo metrics vào Drive.\n",
    "- Đảm bảo cập nhật báo cáo đồ án với bảng kết quả và nhận xét."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b53fb0",
   "metadata": {},
   "source": [
    "## 7. So sánh mô hình\n",
    "Sau khi chạy huấn luyện với các kiến trúc khác nhau, hãy đặt `OUTPUT_DIR` khác nhau cho mỗi lần (ví dụ `artifacts_resnet18`, `artifacts_mobilenet`).\n",
    "Cell dưới đây sẽ đọc các thư mục output đó, tổng hợp Accuracy/Macro F1 trên test và best val acc để bạn so sánh nhanh.\n",
    "Chỉnh sửa biến `EXPERIMENT_DIRS` theo danh sách mô hình bạn đã huấn luyện.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d68cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Tổng hợp kết quả các mô hình đã huấn luyện\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "EXPERIMENT_DIRS = {\n",
    "    \"resnet18\": \"/content/TrashProject/artifacts/resnet18\",\n",
    "    \"mobilenetv3\": \"/content/TrashProject/artifacts/mobilenetv3\",\n",
    "    \"efficientnetb0\": \"/content/TrashProject/artifacts/efficientnetb0\",\n",
    "    \"vit16\": \"/content/TrashProject/artifacts/vit16\"\n",
    "}  # Chỉnh sửa theo các output_dir bạn đã dùng\n",
    "\n",
    "summary = []\n",
    "for name, dir_path in EXPERIMENT_DIRS.items():\n",
    "    dir_path = Path(dir_path)\n",
    "    if not dir_path.exists():\n",
    "        print(f\"[WARN] {dir_path} không tồn tại, bỏ qua.\")\n",
    "        continue\n",
    "    report_path = dir_path / \"classification_report.pth\"\n",
    "    history_path = dir_path / \"history.pth\"\n",
    "    macro_f1 = accuracy = best_val_acc = None\n",
    "\n",
    "    if report_path.exists():\n",
    "        report = torch.load(report_path)\n",
    "        macro_f1 = report.get(\"macro avg\", {}).get(\"f1-score\")\n",
    "        accuracy = report.get(\"accuracy\")\n",
    "    if history_path.exists():\n",
    "        history = torch.load(history_path)\n",
    "        if isinstance(history, dict) and \"val_acc\" in history:\n",
    "            best_val_acc = max(history[\"val_acc\"])\n",
    "\n",
    "    summary.append({\n",
    "        \"model\": name,\n",
    "        \"output_dir\": str(dir_path),\n",
    "        \"test_accuracy\": accuracy,\n",
    "        \"test_macro_f1\": macro_f1,\n",
    "        \"best_val_acc\": best_val_acc,\n",
    "    })\n",
    "\n",
    "if not summary:\n",
    "    print(\"Chưa có kết quả nào. Hãy chạy huấn luyện và lưu output_dir riêng cho từng mô hình.\")\n",
    "else:\n",
    "    header = (\"Model\", \"Output Dir\", \"Test Acc\", \"Test Macro F1\", \"Best Val Acc\")\n",
    "    row_fmt = \"{:<15} {:<40} {:>11} {:>15} {:>13}\"\n",
    "    print(row_fmt.format(*header))\n",
    "    print('-' * 96)\n",
    "    for row in summary:\n",
    "        print(row_fmt.format(\n",
    "            row[\"model\"],\n",
    "            row[\"output_dir\"],\n",
    "            f\"{row['test_accuracy']:.3f}\" if row[\"test_accuracy\"] is not None else \"n/a\",\n",
    "            f\"{row['test_macro_f1']:.3f}\" if row[\"test_macro_f1\"] is not None else \"n/a\",\n",
    "            f\"{row['best_val_acc']:.3f}\" if row[\"best_val_acc\"] is not None else \"n/a\",\n",
    "        ))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
